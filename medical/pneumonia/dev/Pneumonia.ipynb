{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pydicom as dcm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomAffine, RandomResizedCrop\n",
    "import torchmetrics\n",
    "import importlib\n",
    "import pnm.preprocess as preproc\n",
    "importlib.reload(preproc)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at the x-ray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = 'data/stage_2_train_images'\n",
    "label_path = 'data/stage_2_train_labels.csv'\n",
    "\n",
    "num_images = 9\n",
    "labels = pd.read_csv(label_path)\n",
    "dicom_files = [file for file in os.listdir(raw_dir) if file.endswith('.dcm')]\n",
    "\n",
    "# Plot the pixel array of the first 9 DICOM images\n",
    "for i in range(num_images):\n",
    "    file_path = os.path.join(raw_dir, dicom_files[i])\n",
    "    patient_id = os.path.splitext(dicom_files[i])[0]\n",
    "    label = labels[labels['patientId'] == patient_id]['Target'].iloc[0]\n",
    "    ds = dcm.dcmread(file_path)\n",
    "    pixel_array = ds.pixel_array\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.imshow(pixel_array, cmap='bone')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (224, 224)\n",
    "raw_dir = raw_dir\n",
    "label_path = label_path\n",
    "preproc_dir = 'preprocessed'\n",
    "batch_size = 64\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(preproc_dir):\n",
    "    preproc.preprocess(raw_dir, label_path, preproc_dir, shape)\n",
    "    \n",
    "standard_params = preproc.compute_standard_params(preproc_dir, shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(file_name):\n",
    "    # NOTE: The following code breaks at several points (RandomAffine, Trainer.fit()) for np.float16 :(((\n",
    "    return np.load(file_name).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(*standard_params),\n",
    "    RandomAffine(degrees=5, translate=(0, 0.05), scale=(0.9, 1.1)),\n",
    "    RandomResizedCrop(224, scale=(0.35, 1.))\n",
    "])\n",
    "val_transforms = Compose([ToTensor(), Normalize(*standard_params)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DatasetFolder(os.path.join(preproc_dir, 'train'), \n",
    "loader=load_img, extensions='.npy', transform=train_transforms)\n",
    "val_data = DatasetFolder(os.path.join(preproc_dir, 'val'), loader=load_img, extensions='.npy', transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_data.targets, return_counts=True), np.unique(val_data.targets, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    for i in range(3):\n",
    "        rand_idx = np.random.randint(batch[0].shape[0])\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.imshow(batch[0][rand_idx, 0, :, :], cmap='bone')\n",
    "        plt.title(f'label: {batch[1][rand_idx]}')\n",
    "        plt.axis('off')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision.models import resnet18\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics import Accuracy\n",
    "from torch import tensor, sigmoid\n",
    "from torch.nn import BCEWithLogitsLoss, Conv2d, Linear\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaClassifier(LightningModule):\n",
    "\n",
    "    def __init__(self, weight=1, metrics=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = resnet18(pretrained=True)\n",
    "        # Freeze the weights\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.model.conv1 = Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Q: Should bias be False??? in course code its True\n",
    "        self.model.fc = Linear(512, 1, bias=False)\n",
    "\n",
    "        self.metrics = {'acc': Accuracy('binary')} if metrics is None else metrics\n",
    "        self.loss_fn = BCEWithLogitsLoss(pos_weight=tensor(weight))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img, label = batch\n",
    "        logit = self(img)[:,0]\n",
    "        loss = self.loss_fn(logit, label.float())\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        for name, metric in self.metrics.items():\n",
    "            prob = sigmoid(logit)\n",
    "            self.log(f'train_{name}', metric(prob, label.int()), prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_training_epoch_end(self):\n",
    "        for name, metric in self.metrics.items():\n",
    "            self.log('batch_train_{name}', metric.compute())\n",
    "            metric.reset()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img, label = batch\n",
    "        logit = self(img)[:,0]\n",
    "        loss = self.loss_fn(logit, label.float())\n",
    "        self.log('val_loss', loss)\n",
    "        for name, metric in self.metrics.items():\n",
    "            prob = sigmoid(logit)\n",
    "            self.log(f'val_{name}', metric(prob, label.int()), prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        for name, metric in self.metrics.items():\n",
    "            self.log(f'batch_val_{name}', metric.compute())\n",
    "            metric.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnm_model = PneumoniaClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    save_top_k=10,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(logger=TensorBoardLogger(save_dir=\"./logs\"), log_every_n_steps=1,\n",
    "                     callbacks=checkpoint_callback,\n",
    "                     max_epochs=5)\n",
    "trainer.fit(pnm_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path('model')\n",
    "current_date = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "file_name = f'resnet_{current_date}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_dir, exist_ok=True)\n",
    "save(pnm_model.state_dict(), model_dir / file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnm_model = PneumoniaClassifier()\n",
    "pnm_model.load_state_dict(torch.load(model_dir / file_name))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pnm_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_n_labels(model, loader):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            img, label = batch\n",
    "            logit = model(img.to(device))[:,0]\n",
    "            prob = sigmoid(logit)\n",
    "            preds.extend(prob.cpu().numpy())\n",
    "            labels.extend(label.numpy())\n",
    "    \n",
    "    return torch.tensor(preds), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds, train_labels = preds_n_labels(pnm_model, train_loader)\n",
    "val_preds, val_labels = preds_n_labels(pnm_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(preds, labels):\n",
    "    acc = torchmetrics.Accuracy('binary')(preds, labels)\n",
    "    precision = torchmetrics.Precision('binary')(preds, labels)\n",
    "    recall = torchmetrics.Recall('binary')(preds, labels)\n",
    "    auc = torchmetrics.AUROC('binary')(preds, labels)\n",
    "\n",
    "    acc_thresh = torchmetrics.Accuracy('binary', threshold=0.25)(preds, labels)\n",
    "    precision_thresh = torchmetrics.Precision('binary', threshold=0.25)(preds, labels)\n",
    "    recall_thresh = torchmetrics.Recall('binary', threshold=0.25)(preds, labels)\n",
    "\n",
    "    cm = torchmetrics.ConfusionMatrix('binary')(preds, labels)\n",
    "    cm_thresh = torchmetrics.ConfusionMatrix('binary', threshold=0.25)(preds, labels)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f} vs. {acc_thresh:.4f} (threshold=0.25)\")\n",
    "    print(f\"Precision: {precision:.4f} vs. {precision_thresh:.4f} (threshold=0.25)\")\n",
    "    print(f\"Recall: {recall:.4f} vs. {recall_thresh:.4f} (threshold=0.25)\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "    axes[0].set_title('Confusion Matrix (threshold=0.5)')\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('Actual')\n",
    "\n",
    "    sns.heatmap(cm_thresh, annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
    "    axes[1].set_title('Confusion Matrix (threshold=0.25)')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('Actual')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(train_preds, train_labels)\n",
    "evaluate(val_preds, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(train_preds, val_preds, train_labels, val_labels):\n",
    "    train_fpr, train_tpr, _ = torchmetrics.ROC('binary')(train_preds, train_labels)\n",
    "    val_fpr, val_tpr, _ = torchmetrics.ROC('binary')(val_preds, val_labels)\n",
    "    auc = torchmetrics.AUROC('binary')(preds, labels)\n",
    "\n",
    "    plt.plot(train_fpr, train_tpr, label='Training AUC')\n",
    "    plt.plot(val_fpr, val_tpr, label='Validation AUC')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (AUC: {auc:.2f})')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(train_preds, val_preds, train_labels, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "random_indices = np.random.choice(len(val_data), size=9, replace=False)\n",
    "for ax, i in zip(axes.flatten(), random_indices):\n",
    "    ax.imshow(val_data[i][0][0], cmap='bone')\n",
    "    ax.set_title(f\"Prediction: {int(val_preds[i] > 0.25)}, True Label: {val_labels[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
